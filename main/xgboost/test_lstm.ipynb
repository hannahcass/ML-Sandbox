{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffc66bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "from utils.model import TherapeuticRepresentationModel\n",
    "from utils.train import train, eval\n",
    "from utils.preprocessing import extract_librosa_features\n",
    "from utils.dataloader import TherapeuticTracksWithTimesteps\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1edf4d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TherapeuticLSTMClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    This is a LSTM Model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 lstm_input_channels,\n",
    "                 lstm_hidden_size,\n",
    "                 lstm_num_layers,\n",
    "                 linear_num_layers,\n",
    "                 linear_hidden_size,\n",
    "                 linear_output_size,\n",
    "                 h0_size,\n",
    "                 device):\n",
    "        super(TherapeuticLSTMClassifier, self).__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            lstm_input_channels, \n",
    "            lstm_hidden_size, \n",
    "            lstm_num_layers, \n",
    "            batch_first=True, \n",
    "        )\n",
    "\n",
    "        fc_list = [nn.LeakyReLU()]\n",
    "\n",
    "        if linear_num_layers > 1:\n",
    "            fc_list.append(nn.Linear(lstm_hidden_size, linear_hidden_size))\n",
    "            fc_list.append(nn.LeakyReLU())\n",
    "\n",
    "            for _ in range(linear_num_layers-1):\n",
    "                fc_list.append(nn.Linear(linear_hidden_size, linear_hidden_size))\n",
    "                fc_list.append(nn.LeakyReLU())\n",
    "        else:\n",
    "            linear_hidden_size = lstm_hidden_size\n",
    "\n",
    "        fc_list.append(nn.Linear(linear_hidden_size, linear_output_size))\n",
    "        fc_list.append(nn.Sigmoid())\n",
    "\n",
    "        self.mlp = nn.Sequential(*fc_list)\n",
    "        self.h0 = torch.rand(h0_size).double().to(device)\n",
    "        self.c0 = torch.rand(h0_size).double().to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.double()\n",
    "\n",
    "        out, (h0, c0) = self.lstm(x, (self.h0, self.c0))\n",
    "        \n",
    "        #print(out)\n",
    "        #out = out[:, -1]\n",
    "\n",
    "        x = self.mlp(out)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3419fd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_sequences = torch.Tensor(np.array([[0,1,2,3],[1,2,2,3],[1,2,2,1],[1,1,1,0],[1,2,3,4],[5,5,5,3],[4,4,4,5],[1,2,4,4],[4,3,2,1],[3,3,3,1]]))\n",
    "y_s = torch.Tensor(np.array([[0],[0],[1],[1],[0],[1],[0],[0],[1],[1]]))\n",
    "\n",
    "test_some_sequences = torch.Tensor(np.array([[0,0,0,3],[5,5,5,4],[1,1,1,6],[1,1,0,0]]))\n",
    "test_y_s = torch.Tensor(np.array([[0],[1],[0],[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8d8c1747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 2., 3.])\n",
      "tensor([0.])\n",
      "tensor([1., 2., 2., 3.])\n",
      "tensor([0.])\n",
      "tensor([1., 2., 2., 1.])\n",
      "tensor([1.])\n",
      "tensor([1., 1., 1., 0.])\n",
      "tensor([1.])\n",
      "tensor([1., 2., 3., 4.])\n",
      "tensor([0.])\n",
      "tensor([5., 5., 5., 3.])\n",
      "tensor([1.])\n",
      "tensor([4., 4., 4., 5.])\n",
      "tensor([0.])\n",
      "tensor([1., 2., 4., 4.])\n",
      "tensor([0.])\n",
      "tensor([4., 3., 2., 1.])\n",
      "tensor([1.])\n",
      "tensor([3., 3., 3., 1.])\n",
      "tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "for x, y in zip(some_sequences, y_s):\n",
    "    print(x)\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0ae9751a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TherapeuticLSTMClassifier(4, 16, 1, 1, 16, 1, (1, 16), device='cpu')\n",
    "model.double()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a6ce0fd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :  0.7229251008022894\n",
      "1 :  0.7138763772119215\n",
      "2 :  0.7064538383624777\n",
      "3 :  0.6996190937510922\n",
      "4 :  0.6931350165162758\n",
      "5 :  0.6872302855023766\n",
      "6 :  0.6813832127039844\n",
      "7 :  0.6754578686674276\n",
      "8 :  0.6696853524496456\n",
      "9 :  0.6639161406647558\n",
      "10 :  0.6581842202088252\n",
      "11 :  0.6524777212768276\n",
      "12 :  0.6465220853974524\n",
      "13 :  0.640351968737529\n",
      "14 :  0.633209165474818\n",
      "15 :  0.6229146515527253\n",
      "16 :  0.6138465563959202\n",
      "17 :  0.6029401545425521\n",
      "18 :  0.5912773683922652\n",
      "19 :  0.5814131676591466\n",
      "20 :  0.5707487493490541\n",
      "21 :  0.5602790356898174\n",
      "22 :  0.5498915185869667\n",
      "23 :  0.5392108015066202\n",
      "24 :  0.5284420324214492\n",
      "25 :  0.5174654789013337\n",
      "26 :  0.5067873210888457\n",
      "27 :  0.49520123817272016\n",
      "28 :  0.48397096450564075\n",
      "29 :  0.4723673614945745\n",
      "30 :  0.4611894975078238\n",
      "31 :  0.4496761294965313\n",
      "32 :  0.43859389256404235\n",
      "33 :  0.42728492855181954\n",
      "34 :  0.4163664284788927\n",
      "35 :  0.40563688885390564\n",
      "36 :  0.39466080299757633\n",
      "37 :  0.3842816331061468\n",
      "38 :  0.37345630031992144\n",
      "39 :  0.3632788178592541\n",
      "40 :  0.3534021352759872\n",
      "41 :  0.3434797424419148\n",
      "42 :  0.3336978719093081\n",
      "43 :  0.32457656431772713\n",
      "44 :  0.3153705840407669\n",
      "45 :  0.3063137644349225\n",
      "46 :  0.29789850367911713\n",
      "47 :  0.2895063381518087\n",
      "48 :  0.2815773964692124\n",
      "49 :  0.2737569747508629\n",
      "50 :  0.26575290088803977\n",
      "51 :  0.2587266458499177\n",
      "52 :  0.2515576572217645\n",
      "53 :  0.2442869583528592\n",
      "54 :  0.23747305695833631\n",
      "55 :  0.230774870292522\n",
      "56 :  0.2243875130141703\n",
      "57 :  0.21857230937018582\n",
      "58 :  0.21273159668974367\n",
      "59 :  0.2067365256846994\n",
      "60 :  0.20162458779177733\n",
      "61 :  0.19642963159825433\n",
      "62 :  0.19102437130095412\n",
      "63 :  0.18601826374545802\n",
      "64 :  0.18161008573434162\n",
      "65 :  0.17672140626093727\n",
      "66 :  0.17228875854168232\n",
      "67 :  0.16789686800299458\n",
      "68 :  0.1636817802237768\n",
      "69 :  0.15967028424921886\n",
      "70 :  0.1557999521529952\n",
      "71 :  0.15189828396371235\n",
      "72 :  0.14842906427829813\n",
      "73 :  0.14457534791212737\n",
      "74 :  0.14105027113048801\n",
      "75 :  0.13773689809103226\n",
      "76 :  0.13477804129534537\n",
      "77 :  0.13151837277803058\n",
      "78 :  0.12847378450349323\n",
      "79 :  0.1256124439156327\n",
      "80 :  0.12287232990846675\n",
      "81 :  0.12019948622800947\n",
      "82 :  0.11768253800769983\n",
      "83 :  0.11487878565096417\n",
      "84 :  0.11262784491071647\n",
      "85 :  0.1100936809626877\n",
      "86 :  0.10784073092445541\n",
      "87 :  0.10554035519835411\n",
      "88 :  0.10361434772117868\n",
      "89 :  0.10134017436642781\n",
      "90 :  0.0993917607996208\n",
      "91 :  0.09724334217396\n",
      "92 :  0.09544425805979663\n",
      "93 :  0.09345677698848115\n",
      "94 :  0.09180677363317578\n",
      "95 :  0.08986324024598377\n",
      "96 :  0.0882928812784764\n",
      "97 :  0.08670281478767601\n",
      "98 :  0.08503322520764743\n",
      "99 :  0.0835682544573756\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    device='cpu'\n",
    "    epochs = 100\n",
    "    loss_f = nn.BCELoss()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        losses = []\n",
    "        for x, y in zip(some_sequences, y_s):\n",
    "            x = x.to(device).unsqueeze(0).double() # first dimension is batch.\n",
    "            y = y.to(device).unsqueeze(0).double() # first dimension is batch.\n",
    "                        \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            y_hat = model(x)\n",
    "                        \n",
    "            loss = loss_f(y_hat, y)\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        print(epoch, \": \", np.array(losses).mean())\n",
    "            \n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cf4d54c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss:  0.18962018458410898\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    device='cpu'\n",
    "    epochs = 100\n",
    "    loss_f = nn.BCELoss()\n",
    "    \n",
    "    losses = []\n",
    "    for x, y in zip(test_some_sequences, test_y_s):\n",
    "        x = x.to(device).unsqueeze(0).double() # first dimension is batch.\n",
    "        y = y.to(device).unsqueeze(0).double() # first dimension is batch.\n",
    "                                    \n",
    "        y_hat = model(x)\n",
    "                        \n",
    "        loss = loss_f(y_hat, y)\n",
    "        losses.append(loss.item())\n",
    "            \n",
    "               \n",
    "    print(\"Test Loss: \", np.array(losses).mean())\n",
    "    \n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d309cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prac_work",
   "language": "python",
   "name": "prac_work"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
